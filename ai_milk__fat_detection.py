# -*- coding: utf-8 -*-
"""AI_Milk_%fat_detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QWVUKqkdV1klVPOdfeUXUTeoztOlHfGf
"""

#this part involves training the neural network. the preprocessing of data is in a different python file (pycharm)
#Installing the dependencies
from sklearn.model_selection import train_test_split
import numpy as np #linear algebra
import pandas as pd #looking at csv files
from sklearn import neighbors
from sklearn import svm
from sklearn import metrics #accuracy and loss
from sklearn.metrics import scorer

#uploading the dataset
from google.colab import files
uploaded = files.upload()

#looking at the dataset
df = pd.read_csv('AI_%Fat_Prediction.csv')
df.head()

#dropping unwanted columns
#file path(location) is unwanted
New_df = df.drop(columns=['Sno.',"Image","bgr val", "%fat", "SNF")
New_df2 = New_df.drop(columns="Image")
New_df2.head()
New_df3 = New_df2.drop(columns=["bgr val", "%fat", "SNF"])

df.corr()

X = np.array(New_df3['b pixel val'])
X = X.reshape(-1, 1)

y = np.array(df['SNF'])

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)

#using Support Vector Regression to predict results

clf = svm.SVR(kernel='linear',gamma=0.0000000000001, C=0.000000001)
clf.fit(X_train, y_train)

y_pred_svr = clf.predict(X_test)

import sklearn
import sklearn.metrics as sm

print("R2 score =", round(sm.r2_score(y_test, y_pred_svr), 2))
print("Mean absolute error =", round(sm.mean_absolute_error(y_test, y_pred_svr), 2)) 
print("Mean squared error =", round(sm.mean_squared_error(y_test, y_pred_svr), 2)) 
print("Explain variance score =", round(sm.explained_variance_score(y_test, y_pred_svr), 2))

live_data = np.array([[113.8079505]])
prediction_svr = clf.predict(live_data)
print('percentage of fat per litre of milk is: ', prediction_svr)

#now we will use linear regression to compare and contrast.
from sklearn import linear_model
lr = linear_model.LinearRegression()
lr.fit(X_train, y_train)
acc = lr.score(X_train, y_train) 
print(acc)

prediction_lr = lr.predict([[113.8079505]])
print(prediction_lr)

#the final section includes a more complex solution to finding the %fat, Stochastic Gradient Descent
'''
#Installing the Dependencies
from sklearn.linear_model import SGDRegressor
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import scale
import matplotlib.pyplot as plt

'''
x_sgd = np.array(New_df3['b pixel val'])
x_sgd = x.reshape(-1,1)
y_sgd = np.array(df['SNF'])

x_sgd = scale(x)
y_sgd = scale(y)
x_sgd_train, x_sgd_test, y_sgd_train, y_sgd_test = train_test_split(x_sgd, y_sgd, test_size=0.05)

sgdr = SGDRegressor(alpha=0.000000001, epsilon=0.01, eta0=0.1,penalty='elasticnet')
sgdr.fit(x_sgd_train, y_sgd_train)

score = sgdr.score(x_sgd_train, y_sgd_train)
print("R-squared:", score)


y_sgd_pred = sgdr.predict(x_sgd_test)

mse = mean_squared_error(y_sgd_test, y_sgd_pred)
print("MSE: ", mse)

#prediction algorithm
y_sgd_pred = sgdr.predict([[113]])
print(y_sgd_pred)