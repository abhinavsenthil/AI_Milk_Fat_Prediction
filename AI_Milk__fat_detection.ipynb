{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI_Milk_%fat_detection.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNaT8PItFMIWZBSGtoSP5Qr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abhinavsenthil/AI_Milk_Fat_Prediction/blob/main/AI_Milk__fat_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idM-Ivku3_hC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6a54ea4-9c3d-43fe-b019-2c01f7743b50"
      },
      "source": [
        "#this part involves training the neural network. the preprocessing of data is\n",
        "#in a different python file (pycharm)\n",
        "#Installing the dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np #linear algebra\n",
        "import pandas as pd #looking at csv files\n",
        "from sklearn import neighbors\n",
        "from sklearn import svm\n",
        "from sklearn import metrics #accuracy and loss\n",
        "from sklearn.metrics import scorer"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.metrics.scorer module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.metrics. Anything that cannot be imported from sklearn.metrics is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NwLwXD_GnprK",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "6ff160a1-1aed-425e-bc8a-0a7b22d190fb"
      },
      "source": [
        "#uploading the dataset\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d8593cd7-273a-4af7-b70a-b9a52168e684\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d8593cd7-273a-4af7-b70a-b9a52168e684\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving AI_%Fat_Prediction.csv to AI_%Fat_Prediction.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ6uW7Al4bpn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b95f6927-ecb0-406e-8e41-3923609fcf67"
      },
      "source": [
        "#looking at the dataset\n",
        "df = pd.read_csv('AI_%Fat_Prediction.csv')\n",
        "df.tail()\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sno.</th>\n",
              "      <th>Image</th>\n",
              "      <th>b pixel val</th>\n",
              "      <th>g pixel val</th>\n",
              "      <th>r pixel val</th>\n",
              "      <th>bgr val</th>\n",
              "      <th>%fat</th>\n",
              "      <th>SNF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>49</td>\n",
              "      <td>/Users/abhinavsenthil/Desktop/Milk_Project/Val...</td>\n",
              "      <td>142.601094</td>\n",
              "      <td>192.306313</td>\n",
              "      <td>209.600337</td>\n",
              "      <td>[[142.60109427609427], [192.306313131313], [20...</td>\n",
              "      <td>5.7</td>\n",
              "      <td>8.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>50</td>\n",
              "      <td>/Users/abhinavsenthil/Desktop/Milk_Project/Val...</td>\n",
              "      <td>181.791358</td>\n",
              "      <td>225.678515</td>\n",
              "      <td>231.540565</td>\n",
              "      <td>[[181.79135835095138], [225.6785147991542], [2...</td>\n",
              "      <td>5.3</td>\n",
              "      <td>9.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>51</td>\n",
              "      <td>/Users/abhinavsenthil/Desktop/Milk_Project/Val...</td>\n",
              "      <td>162.305820</td>\n",
              "      <td>206.330820</td>\n",
              "      <td>219.474339</td>\n",
              "      <td>[[162.3058201058201], [206.33082010582024], [2...</td>\n",
              "      <td>4.6</td>\n",
              "      <td>9.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>52</td>\n",
              "      <td>/Users/abhinavsenthil/Desktop/Milk_Project/Val...</td>\n",
              "      <td>154.030420</td>\n",
              "      <td>193.981469</td>\n",
              "      <td>205.544895</td>\n",
              "      <td>[[154.03041958041953], [193.98146853146852], [...</td>\n",
              "      <td>5.9</td>\n",
              "      <td>9.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>53</td>\n",
              "      <td>/Users/abhinavsenthil/Desktop/Milk_Project/Val...</td>\n",
              "      <td>180.749828</td>\n",
              "      <td>227.898609</td>\n",
              "      <td>239.488582</td>\n",
              "      <td>[[180.74982829670327], [227.8986092032967], [2...</td>\n",
              "      <td>5.6</td>\n",
              "      <td>9.5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Sno.                                              Image  ...  %fat  SNF\n",
              "48    49  /Users/abhinavsenthil/Desktop/Milk_Project/Val...  ...   5.7  8.7\n",
              "49    50  /Users/abhinavsenthil/Desktop/Milk_Project/Val...  ...   5.3  9.7\n",
              "50    51  /Users/abhinavsenthil/Desktop/Milk_Project/Val...  ...   4.6  9.7\n",
              "51    52  /Users/abhinavsenthil/Desktop/Milk_Project/Val...  ...   5.9  9.7\n",
              "52    53  /Users/abhinavsenthil/Desktop/Milk_Project/Val...  ...   5.6  9.5\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dO2LbE3Q4eZY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "67ae1470-c5a8-48f6-c3cf-f86e8e44b868"
      },
      "source": [
        "#dropping unwanted columns\n",
        "#file path(location) is unwanted\n",
        "New_df = df.drop(columns=['Sno.','bgr val', \"%fat\", \"SNF\"])\n",
        "New_df2 = New_df.drop(columns=\"Image\")\n",
        "New_df2.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>b pixel val</th>\n",
              "      <th>g pixel val</th>\n",
              "      <th>r pixel val</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>172.050529</td>\n",
              "      <td>206.241490</td>\n",
              "      <td>214.861684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>94.051385</td>\n",
              "      <td>150.679615</td>\n",
              "      <td>177.045308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>149.541684</td>\n",
              "      <td>198.814869</td>\n",
              "      <td>218.140575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>170.411855</td>\n",
              "      <td>205.806279</td>\n",
              "      <td>215.099531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>113.807950</td>\n",
              "      <td>159.504789</td>\n",
              "      <td>176.212260</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   b pixel val  g pixel val  r pixel val\n",
              "0   172.050529   206.241490   214.861684\n",
              "1    94.051385   150.679615   177.045308\n",
              "2   149.541684   198.814869   218.140575\n",
              "3   170.411855   205.806279   215.099531\n",
              "4   113.807950   159.504789   176.212260"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "3qSOKiFk5Yn4",
        "outputId": "1c4c133a-0cfb-4f1b-8cb1-4a818c1dda40"
      },
      "source": [
        "df.corr()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sno.</th>\n",
              "      <th>b pixel val</th>\n",
              "      <th>g pixel val</th>\n",
              "      <th>r pixel val</th>\n",
              "      <th>%fat</th>\n",
              "      <th>SNF</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Sno.</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.416686</td>\n",
              "      <td>0.498587</td>\n",
              "      <td>0.501519</td>\n",
              "      <td>-0.215155</td>\n",
              "      <td>0.284340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>b pixel val</th>\n",
              "      <td>0.416686</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.957381</td>\n",
              "      <td>0.874166</td>\n",
              "      <td>-0.232273</td>\n",
              "      <td>0.060303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>g pixel val</th>\n",
              "      <td>0.498587</td>\n",
              "      <td>0.957381</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.971776</td>\n",
              "      <td>-0.220579</td>\n",
              "      <td>0.037583</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>r pixel val</th>\n",
              "      <td>0.501519</td>\n",
              "      <td>0.874166</td>\n",
              "      <td>0.971776</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.174216</td>\n",
              "      <td>0.026939</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>%fat</th>\n",
              "      <td>-0.215155</td>\n",
              "      <td>-0.232273</td>\n",
              "      <td>-0.220579</td>\n",
              "      <td>-0.174216</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.006732</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SNF</th>\n",
              "      <td>0.284340</td>\n",
              "      <td>0.060303</td>\n",
              "      <td>0.037583</td>\n",
              "      <td>0.026939</td>\n",
              "      <td>-0.006732</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 Sno.  b pixel val  ...      %fat       SNF\n",
              "Sno.         1.000000     0.416686  ... -0.215155  0.284340\n",
              "b pixel val  0.416686     1.000000  ... -0.232273  0.060303\n",
              "g pixel val  0.498587     0.957381  ... -0.220579  0.037583\n",
              "r pixel val  0.501519     0.874166  ... -0.174216  0.026939\n",
              "%fat        -0.215155    -0.232273  ...  1.000000 -0.006732\n",
              "SNF          0.284340     0.060303  ... -0.006732  1.000000\n",
              "\n",
              "[6 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1czu33juBsKn"
      },
      "source": [
        "X = np.array(New_df2['b pixel val'])\n",
        "X = X.reshape(-1, 1)\n",
        "\n",
        "y = np.array(df['SNF'])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4oHu5gavCmxZ",
        "outputId": "c1b4a7fb-98a8-4c5d-cb18-b0a250f6f55a"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=0)\n",
        "\n",
        "#using Support Vector Regression to predict results\n",
        "\n",
        "clf = svm.SVR(kernel='linear',gamma=0.0000000000001, C=0.000000001)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred_svr = clf.predict(X_test)\n",
        "\n",
        "import sklearn\n",
        "import sklearn.metrics as sm\n",
        "\n",
        "print(\"R2 score =\", round(sm.r2_score(y_test, y_pred_svr), 2))\n",
        "print(\"Mean absolute error =\", round(sm.mean_absolute_error(y_test, y_pred_svr), 2)) \n",
        "print(\"Mean squared error =\", round(sm.mean_squared_error(y_test, y_pred_svr), 2)) \n",
        "print(\"Explain variance score =\", round(sm.explained_variance_score(y_test, y_pred_svr), 2)) "
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R2 score = -0.61\n",
            "Mean absolute error = 0.12\n",
            "Mean squared error = 0.02\n",
            "Explain variance score = -0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5yoCK58uP_yM",
        "outputId": "ab3513ad-95b7-471f-86a5-c49e5c614a44"
      },
      "source": [
        "#input\n",
        "input_blue_pix_val = float(input('input the number'))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input the number142.601094\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dx02F7ryL3eK",
        "outputId": "acdf00d7-3a95-49d5-c84d-60759b2309d8"
      },
      "source": [
        "#-------\n",
        "live_data = np.array([[input_blue_pix_val]])\n",
        "prediction_svr = clf.predict(live_data)\n",
        "print('percentage of fat per litre of milk is: ', prediction_svr)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "percentage of fat per litre of milk is:  [9.40000125]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4chXOSEXmwfZ",
        "outputId": "138e6bcd-edf0-4eb8-f06e-89821b20e128"
      },
      "source": [
        "#now we will use linear regression to compare and contrast.\n",
        "from sklearn import linear_model\n",
        "lr = linear_model.LinearRegression()\n",
        "lr.fit(X_train, y_train)\n",
        "acc = lr.score(X_train, y_train) \n",
        "print(acc)\n",
        "\n",
        "prediction_lr = lr.predict([[input_blue_pix_val]])\n",
        "print(prediction_lr)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0025015814932071168\n",
            "[9.14876516]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LfgYIwD1PZOF",
        "outputId": "764a96c4-8a5f-483f-e863-ee4cb4c18aff"
      },
      "source": [
        "#USING NEURAL NETWORKS TO FIND MILK SNF/%FAT\n",
        "\n",
        "# Regression Example With Boston Dataset: Baseline\n",
        "from pandas import read_csv\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "# create model\n",
        "model = Sequential()\n",
        "model.add(Dense(150, kernel_initializer='normal', activation='sigmoid'))\n",
        "model.add(Dense(2670, activation='relu'))\n",
        "model.add(Dense(20, kernel_initializer='normal'))\n",
        "model.add(Dense(1, activation='linear'))\n",
        " \n",
        "# Compile model\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])\n",
        "history=model.fit(X_train, y_train, epochs=90, batch_size=256, verbose=1, validation_split=0.2)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/90\n",
            "1/1 [==============================] - 1s 597ms/step - loss: 79.8449 - mse: 79.8449 - mae: 8.8893 - val_loss: 8.9419 - val_mse: 8.9419 - val_mae: 2.9102\n",
            "Epoch 2/90\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 10.0778 - mse: 10.0778 - mae: 3.0940 - val_loss: 5.1327 - val_mse: 5.1327 - val_mae: 2.1589\n",
            "Epoch 3/90\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.9133 - mse: 4.9133 - mae: 2.0229 - val_loss: 23.1030 - val_mse: 23.1030 - val_mae: 4.7573\n",
            "Epoch 4/90\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 22.1223 - mse: 22.1223 - mae: 4.6155 - val_loss: 23.1913 - val_mse: 23.1913 - val_mae: 4.7666\n",
            "Epoch 5/90\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 22.1799 - mse: 22.1799 - mae: 4.6218 - val_loss: 12.7153 - val_mse: 12.7153 - val_mae: 3.4993\n",
            "Epoch 6/90\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 12.0642 - mse: 12.0642 - mae: 3.3535 - val_loss: 3.6400 - val_mse: 3.6400 - val_mae: 1.7805\n",
            "Epoch 7/90\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.4890 - mse: 3.4890 - mae: 1.6341 - val_loss: 0.4837 - val_mse: 0.4837 - val_mae: 0.5633\n",
            "Epoch 8/90\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.8193 - mse: 0.8193 - mae: 0.6184 - val_loss: 1.9090 - val_mse: 1.9090 - val_mae: 1.2145\n",
            "Epoch 9/90\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.6330 - mse: 2.6330 - mae: 1.4924 - val_loss: 4.7681 - val_mse: 4.7681 - val_mae: 2.0734\n",
            "Epoch 10/90\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 5.7497 - mse: 5.7497 - mae: 2.3188 - val_loss: 6.7208 - val_mse: 6.7208 - val_mae: 2.5003\n",
            "Epoch 11/90\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.8320 - mse: 7.8320 - mae: 2.7235 - val_loss: 6.8926 - val_mse: 6.8926 - val_mae: 2.5345\n",
            "Epoch 12/90\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.0196 - mse: 8.0196 - mae: 2.7569 - val_loss: 5.5089 - val_mse: 5.5089 - val_mae: 2.2450\n",
            "Epoch 13/90\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.5581 - mse: 6.5581 - mae: 2.4850 - val_loss: 3.3916 - val_mse: 3.3916 - val_mae: 1.7097\n",
            "Epoch 14/90\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 4.2859 - mse: 4.2859 - mae: 1.9806 - val_loss: 1.4848 - val_mse: 1.4848 - val_mae: 1.0592\n",
            "Epoch 15/90\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.1692 - mse: 2.1692 - mae: 1.3216 - val_loss: 0.5219 - val_mse: 0.5219 - val_mae: 0.6566\n",
            "Epoch 16/90\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.9667 - mse: 0.9667 - mae: 0.7881 - val_loss: 0.7474 - val_mse: 0.7474 - val_mae: 0.6368\n",
            "Epoch 17/90\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.9535 - mse: 0.9535 - mae: 0.6013 - val_loss: 1.8306 - val_mse: 1.8306 - val_mae: 1.1670\n",
            "Epoch 18/90\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 1.8312 - mse: 1.8312 - mae: 1.0072 - val_loss: 3.0291 - val_mse: 3.0291 - val_mae: 1.6001\n",
            "Epoch 19/90\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.8880 - mse: 2.8880 - mae: 1.4391 - val_loss: 3.6476 - val_mse: 3.6476 - val_mae: 1.7829\n",
            "Epoch 20/90\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.4453 - mse: 3.4453 - mae: 1.6213 - val_loss: 3.4230 - val_mse: 3.4230 - val_mae: 1.7188\n",
            "Epoch 21/90\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.2410 - mse: 3.2410 - mae: 1.5570 - val_loss: 2.5703 - val_mse: 2.5703 - val_mae: 1.4497\n",
            "Epoch 22/90\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.4758 - mse: 2.4758 - mae: 1.2880 - val_loss: 1.5543 - val_mse: 1.5543 - val_mae: 1.0420\n",
            "Epoch 23/90\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.5926 - mse: 1.5926 - mae: 0.8876 - val_loss: 0.7886 - val_mse: 0.7886 - val_mae: 0.6514\n",
            "Epoch 24/90\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.9814 - mse: 0.9814 - mae: 0.6108 - val_loss: 0.4769 - val_mse: 0.4769 - val_mae: 0.5686\n",
            "Epoch 25/90\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8216 - mse: 0.8216 - mae: 0.6276 - val_loss: 0.5709 - val_mse: 0.5709 - val_mae: 0.6914\n",
            "Epoch 26/90\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.0462 - mse: 1.0462 - mae: 0.8336 - val_loss: 0.8570 - val_mse: 0.8570 - val_mae: 0.8129\n",
            "Epoch 27/90\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.4277 - mse: 1.4277 - mae: 1.0341 - val_loss: 1.1128 - val_mse: 1.1128 - val_mae: 0.9096\n",
            "Epoch 28/90\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.7398 - mse: 1.7398 - mae: 1.1630 - val_loss: 1.1958 - val_mse: 1.1958 - val_mae: 0.9396\n",
            "Epoch 29/90\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 1.8393 - mse: 1.8393 - mae: 1.2006 - val_loss: 1.0902 - val_mse: 1.0902 - val_mae: 0.9009\n",
            "Epoch 30/90\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.7140 - mse: 1.7140 - mae: 1.1531 - val_loss: 0.8544 - val_mse: 0.8544 - val_mae: 0.8118\n",
            "Epoch 31/90\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.4256 - mse: 1.4256 - mae: 1.0326 - val_loss: 0.6104 - val_mse: 0.6104 - val_mae: 0.7139\n",
            "Epoch 32/90\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.1045 - mse: 1.1045 - mae: 0.8672 - val_loss: 0.4762 - val_mse: 0.4762 - val_mae: 0.6045\n",
            "Epoch 33/90\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8779 - mse: 0.8779 - mae: 0.7132 - val_loss: 0.5133 - val_mse: 0.5133 - val_mae: 0.5753\n",
            "Epoch 34/90\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8194 - mse: 0.8194 - mae: 0.5893 - val_loss: 0.6979 - val_mse: 0.6979 - val_mae: 0.6293\n",
            "Epoch 35/90\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.9173 - mse: 0.9173 - mae: 0.5924 - val_loss: 0.9293 - val_mse: 0.9293 - val_mae: 0.7107\n",
            "Epoch 36/90\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 1.0835 - mse: 1.0835 - mae: 0.6506 - val_loss: 1.0895 - val_mse: 1.0895 - val_mae: 0.7931\n",
            "Epoch 37/90\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 1.2079 - mse: 1.2079 - mae: 0.7045 - val_loss: 1.1073 - val_mse: 1.1073 - val_mae: 0.8020\n",
            "Epoch 38/90\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.2219 - mse: 1.2219 - mae: 0.7102 - val_loss: 0.9875 - val_mse: 0.9875 - val_mae: 0.7390\n",
            "Epoch 39/90\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.1279 - mse: 1.1279 - mae: 0.6698 - val_loss: 0.7957 - val_mse: 0.7957 - val_mae: 0.6532\n",
            "Epoch 40/90\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.9846 - mse: 0.9846 - mae: 0.6125 - val_loss: 0.6127 - val_mse: 0.6127 - val_mae: 0.6096\n",
            "Epoch 41/90\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8642 - mse: 0.8642 - mae: 0.5817 - val_loss: 0.4994 - val_mse: 0.4994 - val_mae: 0.5684\n",
            "Epoch 42/90\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8170 - mse: 0.8170 - mae: 0.5980 - val_loss: 0.4687 - val_mse: 0.4687 - val_mae: 0.5894\n",
            "Epoch 43/90\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.8466 - mse: 0.8466 - mae: 0.6742 - val_loss: 0.4907 - val_mse: 0.4907 - val_mae: 0.6224\n",
            "Epoch 44/90\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.9128 - mse: 0.9128 - mae: 0.7449 - val_loss: 0.5195 - val_mse: 0.5195 - val_mae: 0.6531\n",
            "Epoch 45/90\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.9667 - mse: 0.9667 - mae: 0.7843 - val_loss: 0.5264 - val_mse: 0.5264 - val_mae: 0.6590\n",
            "Epoch 46/90\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.9782 - mse: 0.9782 - mae: 0.7919 - val_loss: 0.5075 - val_mse: 0.5075 - val_mae: 0.6418\n",
            "Epoch 47/90\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.9453 - mse: 0.9453 - mae: 0.7697 - val_loss: 0.4808 - val_mse: 0.4808 - val_mae: 0.6093\n",
            "Epoch 48/90\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8907 - mse: 0.8907 - mae: 0.7250 - val_loss: 0.4687 - val_mse: 0.4687 - val_mae: 0.5856\n",
            "Epoch 49/90\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8401 - mse: 0.8401 - mae: 0.6639 - val_loss: 0.4886 - val_mse: 0.4886 - val_mae: 0.5685\n",
            "Epoch 50/90\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8172 - mse: 0.8172 - mae: 0.6099 - val_loss: 0.5395 - val_mse: 0.5395 - val_mae: 0.5870\n",
            "Epoch 51/90\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.8275 - mse: 0.8275 - mae: 0.5826 - val_loss: 0.6007 - val_mse: 0.6007 - val_mae: 0.6066\n",
            "Epoch 52/90\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8570 - mse: 0.8570 - mae: 0.5812 - val_loss: 0.6435 - val_mse: 0.6435 - val_mae: 0.6176\n",
            "Epoch 53/90\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.8819 - mse: 0.8819 - mae: 0.5841 - val_loss: 0.6498 - val_mse: 0.6498 - val_mae: 0.6191\n",
            "Epoch 54/90\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8857 - mse: 0.8857 - mae: 0.5851 - val_loss: 0.6203 - val_mse: 0.6203 - val_mae: 0.6118\n",
            "Epoch 55/90\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8680 - mse: 0.8680 - mae: 0.5819 - val_loss: 0.5711 - val_mse: 0.5711 - val_mae: 0.5978\n",
            "Epoch 56/90\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8414 - mse: 0.8414 - mae: 0.5800 - val_loss: 0.5225 - val_mse: 0.5225 - val_mae: 0.5800\n",
            "Epoch 57/90\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.8215 - mse: 0.8215 - mae: 0.5865 - val_loss: 0.4888 - val_mse: 0.4888 - val_mae: 0.5685\n",
            "Epoch 58/90\n",
            "1/1 [==============================] - 0s 167ms/step - loss: 0.8171 - mse: 0.8171 - mae: 0.6098 - val_loss: 0.4728 - val_mse: 0.4728 - val_mae: 0.5748\n",
            "Epoch 59/90\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8264 - mse: 0.8264 - mae: 0.6389 - val_loss: 0.4689 - val_mse: 0.4689 - val_mae: 0.5858\n",
            "Epoch 60/90\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.8401 - mse: 0.8401 - mae: 0.6641 - val_loss: 0.4691 - val_mse: 0.4691 - val_mae: 0.5907\n",
            "Epoch 61/90\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8483 - mse: 0.8483 - mae: 0.6767 - val_loss: 0.4690 - val_mse: 0.4690 - val_mae: 0.5895\n",
            "Epoch 62/90\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.8461 - mse: 0.8461 - mae: 0.6735 - val_loss: 0.4694 - val_mse: 0.4694 - val_mae: 0.5828\n",
            "Epoch 63/90\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8357 - mse: 0.8357 - mae: 0.6572 - val_loss: 0.4748 - val_mse: 0.4748 - val_mae: 0.5722\n",
            "Epoch 64/90\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8238 - mse: 0.8238 - mae: 0.6327 - val_loss: 0.4883 - val_mse: 0.4883 - val_mae: 0.5686\n",
            "Epoch 65/90\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8170 - mse: 0.8170 - mae: 0.6105 - val_loss: 0.5089 - val_mse: 0.5089 - val_mae: 0.5735\n",
            "Epoch 66/90\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8179 - mse: 0.8179 - mae: 0.5912 - val_loss: 0.5308 - val_mse: 0.5308 - val_mae: 0.5834\n",
            "Epoch 67/90\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8240 - mse: 0.8240 - mae: 0.5841 - val_loss: 0.5463 - val_mse: 0.5463 - val_mae: 0.5893\n",
            "Epoch 68/90\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.8299 - mse: 0.8299 - mae: 0.5814 - val_loss: 0.5499 - val_mse: 0.5499 - val_mae: 0.5906\n",
            "Epoch 69/90\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8313 - mse: 0.8313 - mae: 0.5808 - val_loss: 0.5413 - val_mse: 0.5413 - val_mae: 0.5874\n",
            "Epoch 70/90\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.8277 - mse: 0.8277 - mae: 0.5821 - val_loss: 0.5247 - val_mse: 0.5247 - val_mae: 0.5808\n",
            "Epoch 71/90\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.8218 - mse: 0.8218 - mae: 0.5857 - val_loss: 0.5063 - val_mse: 0.5063 - val_mae: 0.5721\n",
            "Epoch 72/90\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.8173 - mse: 0.8173 - mae: 0.5925 - val_loss: 0.4912 - val_mse: 0.4912 - val_mae: 0.5686\n",
            "Epoch 73/90\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.8165 - mse: 0.8165 - mae: 0.6069 - val_loss: 0.4815 - val_mse: 0.4815 - val_mae: 0.5686\n",
            "Epoch 74/90\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.8189 - mse: 0.8189 - mae: 0.6201 - val_loss: 0.4766 - val_mse: 0.4766 - val_mae: 0.5703\n",
            "Epoch 75/90\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.8220 - mse: 0.8220 - mae: 0.6288 - val_loss: 0.4751 - val_mse: 0.4751 - val_mae: 0.5721\n",
            "Epoch 76/90\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8234 - mse: 0.8234 - mae: 0.6322 - val_loss: 0.4763 - val_mse: 0.4763 - val_mae: 0.5708\n",
            "Epoch 77/90\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.8223 - mse: 0.8223 - mae: 0.6295 - val_loss: 0.4802 - val_mse: 0.4802 - val_mae: 0.5687\n",
            "Epoch 78/90\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.8195 - mse: 0.8195 - mae: 0.6223 - val_loss: 0.4872 - val_mse: 0.4872 - val_mae: 0.5688\n",
            "Epoch 79/90\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.8169 - mse: 0.8169 - mae: 0.6120 - val_loss: 0.4966 - val_mse: 0.4966 - val_mae: 0.5688\n",
            "Epoch 80/90\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.8161 - mse: 0.8161 - mae: 0.6009 - val_loss: 0.5067 - val_mse: 0.5067 - val_mae: 0.5724\n",
            "Epoch 81/90\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8170 - mse: 0.8170 - mae: 0.5922 - val_loss: 0.5148 - val_mse: 0.5148 - val_mae: 0.5764\n",
            "Epoch 82/90\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.8185 - mse: 0.8185 - mae: 0.5885 - val_loss: 0.5184 - val_mse: 0.5184 - val_mae: 0.5781\n",
            "Epoch 83/90\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.8193 - mse: 0.8193 - mae: 0.5873 - val_loss: 0.5169 - val_mse: 0.5169 - val_mae: 0.5775\n",
            "Epoch 84/90\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8188 - mse: 0.8188 - mae: 0.5878 - val_loss: 0.5111 - val_mse: 0.5111 - val_mae: 0.5748\n",
            "Epoch 85/90\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.8174 - mse: 0.8174 - mae: 0.5899 - val_loss: 0.5033 - val_mse: 0.5033 - val_mae: 0.5708\n",
            "Epoch 86/90\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.8161 - mse: 0.8161 - mae: 0.5948 - val_loss: 0.4957 - val_mse: 0.4957 - val_mae: 0.5694\n",
            "Epoch 87/90\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.8156 - mse: 0.8156 - mae: 0.6020 - val_loss: 0.4898 - val_mse: 0.4898 - val_mae: 0.5696\n",
            "Epoch 88/90\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.8161 - mse: 0.8161 - mae: 0.6089 - val_loss: 0.4863 - val_mse: 0.4863 - val_mae: 0.5698\n",
            "Epoch 89/90\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.8168 - mse: 0.8168 - mae: 0.6136 - val_loss: 0.4852 - val_mse: 0.4852 - val_mae: 0.5700\n",
            "Epoch 90/90\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.8172 - mse: 0.8172 - mae: 0.6152 - val_loss: 0.4863 - val_mse: 0.4863 - val_mae: 0.5702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be0WbvvNRMYs",
        "outputId": "d204477a-002c-4140-9bb7-d9aba982be27"
      },
      "source": [
        "#predicting the milk fat/SNF value using the above neural network\n",
        "predictions_NN = model.predict([[input_blue_pix_val]])\n",
        "print(predictions_NN)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[9.142658]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Nt0VSeGOrXf",
        "outputId": "63e2d60c-dcbd-4557-d5e4-020f09feb6d5"
      },
      "source": [
        "Final_SNF_amt = float(predictions_NN[0][0])*0.25 + float(prediction_lr[0])*0.3 + float(prediction_svr[0])*0.45\n",
        "Adj_SNF_amt = float(Final_SNF_amt/10.5)*10\n",
        "print('fat/SNF amount: ' , Adj_SNF_amt)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fat/SNF amount:  8.81932825541112\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lXLdnFsUH0x"
      },
      "source": [
        "model.save('keras.h5')"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5Si7yRtURN8",
        "outputId": "f8aa133a-de7e-4ed0-800f-34cba54363f5"
      },
      "source": [
        "!pip install tensorflowjs"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflowjs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fe/7e/b005271236ddb90fb8a85e29e32ba0841e6737faf9068adbc5ca28df6a41/tensorflowjs-2.8.1-py3-none-any.whl (63kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: h5py<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.10.0)\n",
            "Requirement already satisfied: six<2,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (1.15.0)\n",
            "Requirement already satisfied: tensorflow<3,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflowjs) (2.4.0)\n",
            "Collecting tensorflow-hub<0.10,>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ac/83/a7df82744a794107641dad1decaad017d82e25f0e1f761ac9204829eef96/tensorflow_hub-0.9.0-py2.py3-none-any.whl (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 8.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py<3,>=2.8.0->tensorflowjs) (1.19.4)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.3.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.2.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.12.4)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (2.4.0)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.32.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12.1)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.10.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.1.2)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.12)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (1.6.3)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow<3,>=2.1.0->tensorflowjs) (0.36.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tensorflow<3,>=2.1.0->tensorflowjs) (50.3.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.7.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.17.2)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (2020.12.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (4.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow<3,>=2.1.0->tensorflowjs) (0.4.8)\n",
            "Installing collected packages: tensorflow-hub, tensorflowjs\n",
            "  Found existing installation: tensorflow-hub 0.10.0\n",
            "    Uninstalling tensorflow-hub-0.10.0:\n",
            "      Successfully uninstalled tensorflow-hub-0.10.0\n",
            "Successfully installed tensorflow-hub-0.9.0 tensorflowjs-2.8.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ko19fmlkUXE5",
        "outputId": "4815cdd9-b2b8-4021-f2c0-42513d9cd445"
      },
      "source": [
        "!mkdir model\n",
        "!tensorflowjs_converter --input_format keras keras.h5 model/"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-18 14:48:01.730186: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kOv-m5JyUosG",
        "outputId": "5d6f2ebc-4bbe-4dc5-8b3d-22353483a413"
      },
      "source": [
        "!zip -r model.zip model"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: model/ (stored 0%)\n",
            "  adding: model/group1-shard1of1.bin (deflated 8%)\n",
            "  adding: model/model.json (deflated 77%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-xXKkQnnUvJa",
        "outputId": "e68a120c-524a-4bd9-e6d3-746409460dc6"
      },
      "source": [
        "from google.colab import files\n",
        "files.download('model.zip')"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_f25486fc-9068-4994-a6b4-1981dd4bc6b2\", \"model.zip\", 1683407)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}